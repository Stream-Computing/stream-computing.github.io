<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-希姆计算软件产品/STCRP使用指南/STC_LLM使用指南" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.1">
<title data-rh="true">STC_LLM使用指南 | 文档中心</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-docusaurus-site.example.com/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-docusaurus-site.example.com/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-docusaurus-site.example.com/docs/希姆计算软件产品/STCRP使用指南/STC_LLM使用指南"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="STC_LLM使用指南 | 文档中心"><meta data-rh="true" name="description" content="STC_LLM概述"><meta data-rh="true" property="og:description" content="STC_LLM概述"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-docusaurus-site.example.com/docs/希姆计算软件产品/STCRP使用指南/STC_LLM使用指南"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/docs/希姆计算软件产品/STCRP使用指南/STC_LLM使用指南" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/docs/希姆计算软件产品/STCRP使用指南/STC_LLM使用指南" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"STC_LLM使用指南","item":"https://your-docusaurus-site.example.com/docs/希姆计算软件产品/STCRP使用指南/STC_LLM使用指南"}]}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="文档中心 RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="文档中心 Atom Feed"><link rel="stylesheet" href="/assets/css/styles.59b7a052.css">
<script src="/assets/js/runtime~main.462312d6.js" defer="defer"></script>
<script src="/assets/js/main.3e5567e0.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/stc_logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/stc_logo.svg" alt="" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/stc_logo.svg" alt="" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">STC DOCS HUB</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">文档</a><a class="navbar__item navbar__link" href="/blog">动态</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://www.streamcomputing.com/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">希姆计算<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro"><span title="Tutorial Intro" class="linkLabel_WmDU">Tutorial Intro</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/docs/category/tutorial---basics"><span title="Tutorial - Basics" class="categoryLinkLabel_W154">Tutorial - Basics</span></a><button aria-label="Expand sidebar category &#x27;Tutorial - Basics&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/docs/category/tutorial---extras"><span title="Tutorial - Extras" class="categoryLinkLabel_W154">Tutorial - Extras</span></a><button aria-label="Expand sidebar category &#x27;Tutorial - Extras&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/希姆计算产品运维/k8s-device-plugin使用指南"><span title="希姆计算产品运维" class="categoryLinkLabel_W154">希姆计算产品运维</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/希姆计算介绍"><span title="希姆计算" class="linkLabel_WmDU">希姆计算</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/希姆计算开发者资源/C++ API"><span title="希姆计算开发者资源" class="categoryLinkLabel_W154">希姆计算开发者资源</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/希姆计算术语表"><span title="希姆计算术语表" class="linkLabel_WmDU">希姆计算术语表</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/希姆计算硬件产品/STCP920产品手册"><span title="希姆计算硬件产品" class="categoryLinkLabel_W154">希姆计算硬件产品</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/希姆计算解决方案/希姆算力云平台解决方案"><span title="希姆计算解决方案" class="categoryLinkLabel_W154">希姆计算解决方案</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/希姆计算软件产品/Firmware Release Notes"><span title="希姆计算软件产品" class="categoryLinkLabel_W154">希姆计算软件产品</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/希姆计算软件产品/Firmware Release Notes"><span title="Firmware Release Notes" class="linkLabel_WmDU">Firmware Release Notes</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/希姆计算软件产品/STCRP Release Notes"><span title="STCRP Release Notes" class="linkLabel_WmDU">STCRP Release Notes</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/希姆计算软件产品/STCRP产品简介"><span title="STCRP产品简介" class="linkLabel_WmDU">STCRP产品简介</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/希姆计算软件产品/STCRP使用指南/HPE使用指南"><span title="STCRP使用指南" class="categoryLinkLabel_W154">STCRP使用指南</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/希姆计算软件产品/STCRP使用指南/HPE使用指南"><span title="HPE使用指南" class="linkLabel_WmDU">HPE使用指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/希姆计算软件产品/STCRP使用指南/MLTC使用指南"><span title="MLTC使用指南" class="linkLabel_WmDU">MLTC使用指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/希姆计算软件产品/STCRP使用指南/STC_LLM使用指南"><span title="STC_LLM使用指南" class="linkLabel_WmDU">STC_LLM使用指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/希姆计算软件产品/STCRP使用指南/npu-exporter使用说明"><span title="npu-exporter使用说明" class="linkLabel_WmDU">npu-exporter使用说明</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/希姆计算软件产品/STCRP使用指南/stcqual使用指南"><span title="stcqual使用指南" class="linkLabel_WmDU">stcqual使用指南</span></a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/希姆计算软件产品/STCRP安装指南"><span title="STCRP安装指南" class="linkLabel_WmDU">STCRP安装指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/希姆计算软件产品/固件更新指南"><span title="固件更新指南" class="linkLabel_WmDU">固件更新指南</span></a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">希姆计算软件产品</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">STCRP使用指南</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">STC_LLM使用指南</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>STC_LLM使用指南</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="stc_llm概述">STC_LLM概述<a href="#stc_llm概述" class="hash-link" aria-label="Direct link to STC_LLM概述" title="Direct link to STC_LLM概述" translate="no">​</a></h2>
<p>本文档以chatglm3-6b模型为例，演示如何基于希姆计算软硬件部署LLM，提供推理服务、处理推理任务并监控推理过程中的指标。</p>
<p>主流的开源LLM往往基于HuggingFace等格式，权重保存为bin或者safetensors，为更高效地完成LLM推理任务，希姆计算面向LLM自研了推理框架STC_LLM。STC_LLM在AI编译器、手写算子的基础上对LLM的推理过程进行了封装，您可以方便地导入、替换LLM并完成推理任务，简化了LLM的部署和使用过程。</p>
<p>STC_LLM面向LLM支持以下特性：</p>
<ul>
<li>编译阶段：支持权重转换、量化预处理、Tensor并行处理超大规模的权重等。</li>
<li>服务阶段：支持动态batch管理优化端到端吞吐。</li>
<li>推理阶段：支持kernel级别的优化、KV Cache优化等。</li>
</ul>
<p>基于STC_LLM的典型推理流程如下图所示：</p>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/stc_llm-01-725f9266858c27383ce275b48797e8a1.png" width="1124" height="476" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="部署模型">部署模型<a href="#部署模型" class="hash-link" aria-label="Direct link to 部署模型" title="Direct link to 部署模型" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="前提条件">前提条件<a href="#前提条件" class="hash-link" aria-label="Direct link to 前提条件" title="Direct link to 前提条件" translate="no">​</a></h3>
<ul>
<li>确保服务器的内存满足模型的要求，例如chatglm3-6b的HuggingFace项目文件大小在13G左右，在转换权重时还会创建副本，因此需要配备尽量大的内存。</li>
<li>确保能访问HuggingFace等渠道，且可以下载带有LFS标记的文件。</li>
<li>准备好希姆计算LLM推理环境，安装HPE、Python v3.10、HPE Python、STC_LLM、STC_LLM_DNN。具体操作，请参见<a href="https://docs.streamcomputing.com/_/sharing/vSxLMI20nalGphdpXdEVoDg6JkUcfEkT?next=/zh/latest/" target="_blank" rel="noopener noreferrer">STCRP安装指南</a>。</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="部署流程">部署流程<a href="#部署流程" class="hash-link" aria-label="Direct link to 部署流程" title="Direct link to 部署流程" translate="no">​</a></h3>
<p>以chatglm3-6b为例演示部署步骤：</p>
<ol>
<li>
<p>设置环境变量。</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ export RISCV=/usr/local/hpe</span><br></span></code></pre></div></div>
</li>
<li>
<p>从HuggingFace等渠道获取<a href="https://huggingface.co/THUDM/chatglm3-6b/tree/main" target="_blank" rel="noopener noreferrer">chatglm3-6b</a>的文件，包括包括模型文件、权重文件、分词器文件、词表等，并复制到目标服务器。</p>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/stc_llm-02-2b6b8152a3a40f68906d423596ae6508.png" width="1280" height="723" class="img_ev3q"></p>
</li>
<li>
<p>编写Python脚本部署并验证模型。脚本示例中主要包括以下步骤：</p>
<ol>
<li>
<p>准备模型配置，支持的配置项请参见<em>模型配置</em>章节。</p>
</li>
<li>
<p>调用<code>AutoGeneration4.from_config</code>接口部署模型。</p>
</li>
<li>
<p>发送messages验证LLM的对话效果。</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ cat test_chatglm3-6b.py</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import asyncio</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from stc_llm_dnn.runtime import AsyncGeneration</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">async def print_stream(gen, model, gen_name, prompt):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    async for task in gen:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        print(&quot;[{}] prompt = {}, gen = {}&quot;.format(gen_name, prompt, model.decode_token_ids(task.gen_tokens)))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">async def test_async_generation():</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 配置信息</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    config = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;model_name&quot;: &quot;THUDM/chatglm3-6b&quot;,           # 模型名称</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;devices&quot;: [0, 1],                           # 使用的 npu id 列表</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;tok_dir&quot;: &quot;./chatglm3-6b&quot;,             # tokenizer 目录</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;original_weight_dir&quot;: &quot;./chatglm3-6b&quot;, # 原始权重路径</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;weight_dir&quot;: &quot;chatglm2-6b-2npu-dataset&quot;,    # 转换后权重路径</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;max_tasks&quot;: 256,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;custom_parameters&quot;: True,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;quant_type&quot;: &quot;fp16&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;compress_factor&quot;: 1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 创建 generation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    generation = AsyncGeneration(config)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 运行测试</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    messages = [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;你是资深的技术支持专家，可以为用户提供希姆计算软硬件产品的技术支持，解答用户使用产品时的疑问。&quot;},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你好，你是谁啊？&quot;},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    task = await generation.create_task(messages=messages, temperature=0.5, top_p=0.2, top_k=20, max_output_len=256)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    gen = generation.generate_stream(task)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    user_task = asyncio.create_task(print_stream(gen, generation.model, f&quot;gen&quot;, &quot;你好&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    await user_task</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    await generation.shutdown()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if __name__ == &quot;__main__&quot;:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    asyncio.run(test_async_generation())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ python3 test_chatglm3-6b.py</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 忽略部分回显</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---------------------------- Model Info Begin ----------------------------</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model name: THUDM/chatglm3-6b</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">npus: [0, 1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">total slot number: 157053</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">slot number per segment: 256</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">total segment number: 613</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">bytes per slot: 14336</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">temporary cpp dir: /home/superadmin/.cache/stc_llm_dnn/THUDM/chatglm3-6b</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer dir: ./chatglm3-6b</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">weight dir: chatglm2-6b-2npu-dataset</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">embedding on host: False</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">output on host: False</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dma preload: True</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">max sequence length: 8192</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compress_factor: 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">quant_type: fp16</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---------------------------- Model Info End ----------------------------</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 忽略部分回显</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[gen] prompt = 你好, gen =</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> 你好，我是希姆计算的资深技术支持专家，很高兴为您提供技术支持。请问有什么软硬件产品需要我帮助您解答疑问吗？</span><br></span></code></pre></div></div>
</li>
</ol>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="模型配置">模型配置<a href="#模型配置" class="hash-link" aria-label="Direct link to 模型配置" title="Direct link to 模型配置" translate="no">​</a></h3>
<p>部署模型时支持的模型配置如下表所示：</p>
<table><thead><tr><th><strong>配置项</strong></th><th><strong>是否必填</strong></th><th><strong>数据类型</strong></th><th><strong>示例</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td>model_name</td><td>是</td><td>str</td><td>THUDM/chatglm3-6b</td><td>待部署模型的名称，建议与HuggingFace等渠道中的名称保持一致。</td></tr><tr><td>devices</td><td>是</td><td>list</td><td>[0, 1]</td><td>模型推理时占用NPU设备的ID列表，STC_LLM会根据NPU设备的数量将原始权重自动切分为匹配的份数。</td></tr><tr><td>tok_dir</td><td>是</td><td>str</td><td>./chatglm3-6b</td><td>加载模型的分词器（tokenizer）文件的路径。</td></tr><tr><td>original_weight_dir</td><td>否</td><td>str</td><td>./chatglm3-6b</td><td>加载模型的原始权重文件的路径。如果您没有在目标服务器上转换过权重，则至少需要从原始权重转换一次，这时<code>original_weight_dir</code>为必填项。</td></tr><tr><td>weight_dir</td><td>否</td><td>str</td><td>chatglm3-6b-2npu-dataset</td><td>从原始权重转换后可以在NPU设备上使用的权重的路径。<br>如果<code>weight_dir</code>指向的路径存在权重文件，则使用这些权重。<br>如果<code>weight_dir</code>指向的路径不存在权重文件，则STC_LLM尝试从<code>original_weight_dir</code>获取原始权重进行转换，并将转换后的权重放到<code>weight_dir</code>指向的路径。</td></tr><tr><td>max_tasks</td><td>否</td><td>int</td><td>256</td><td>支持同时执行的最大task数量，每个task分配一个stream完成一轮对话。默认值：256。</td></tr><tr><td>custom_parameters</td><td>否</td><td>bool</td><td>False</td><td>True：允许task自定义temperature、top_p、top_k、logprobs、top_logprobs。<br>False：默认值。禁止task自定义temperature、top_p、top_k、logprobs、top_logprobs。</td></tr><tr><td>temperature</td><td>否</td><td>float</td><td>0.5</td><td>超参数之一，控制生成输出的随机性，值越低保证更多的确定性，值越高引入更多的随机性。需要将custom_parameters配置为True才可以修改，默认值：0.5，数值范围为[0.0, 2.0]。</td></tr><tr><td>top_p</td><td>否</td><td>float</td><td>0.2</td><td>超参数之一，在生成输出抽样时排除累积概率低于该值的token。需要将custom_parameters配置为True才可以修改，默认值：0.2，数值范围为(0.0, 1.0]。</td></tr><tr><td>top_k</td><td>否</td><td>int</td><td>20</td><td>超参数之一，在生成输出抽样时只在概率top k个token中进行。需要将custom_parameters配置为True才可以修改，默认值：20，数值范围为[1, 词表长度]。</td></tr><tr><td><internal>dma_preload</internal></td><td>否</td><td>bool</td><td>True</td><td>True：默认值。启用DMA预取，通过拷贝权重、矩阵计算等并行操作加速推理。<br>False：禁用DMA预取。</td></tr><tr><td><internal>render_cpp</internal></td><td>否</td><td>bool</td><td>True</td><td>True：默认值。部署模型时重新生成并覆盖当前的模型代码（cpp）文件。<br>False：部署模型时使用当前的模型代码（cpp）文件，不重新生成。</td></tr><tr><td>quant_type</td><td>否</td><td>str</td><td>fp16</td><td>指定是否通过量化节省内存空间。fp16：默认值，不启用压缩。w8a16：启用压缩。</td></tr><tr><td>compress_factor</td><td>否</td><td>int</td><td>64</td><td>压缩倍数，仅在<code>quant_type</code>为<code>w8a16</code>时生效，支持的压缩倍数包括128、64、32、16、8、1、-1，压缩倍数越高，能节省的内存空间越多。压缩倍数为-1时对应per-channel方式。</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="问题排查">问题排查<a href="#问题排查" class="hash-link" aria-label="Direct link to 问题排查" title="Direct link to 问题排查" translate="no">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="未设置risc-v环境变量">未设置RISC-V环境变量<a href="#未设置risc-v环境变量" class="hash-link" aria-label="Direct link to 未设置RISC-V环境变量" title="Direct link to 未设置RISC-V环境变量" translate="no">​</a></h4>
<ul>
<li>
<p>问题现象：执行脚本示例时报错<code>RuntimeError(&quot;Can</code>t find RISCV environment variable&quot;)`。</p>
</li>
<li>
<p>解决方式：必须设置RISC-V环境变量。</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ export RISCV=/usr/local/hpe</span><br></span></code></pre></div></div>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="可用内存不足">可用内存不足<a href="#可用内存不足" class="hash-link" aria-label="Direct link to 可用内存不足" title="Direct link to 可用内存不足" translate="no">​</a></h4>
<ul>
<li>
<p>问题现象：执行脚本示例时报错<code>run weight convert ... Killed</code>。</p>
</li>
<li>
<p>解决方式：查看可用内存是否足以放下模型、权重等文件。</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ free -h</span><br></span></code></pre></div></div>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="提供推理服务">提供推理服务<a href="#提供推理服务" class="hash-link" aria-label="Direct link to 提供推理服务" title="Direct link to 提供推理服务" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="使用流程">使用流程<a href="#使用流程" class="hash-link" aria-label="Direct link to 使用流程" title="Direct link to 使用流程" translate="no">​</a></h3>
<p>STC_LLM中封装了OpenAI风格的接口，服务端可以提供推理服务并处理推理请求，客户端通过Python脚本、curl命令等方式和LLM交互。</p>
<ol>
<li>
<p>准备模型配置，并在服务端启动推理服务。</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ python3 -m stc_llm.entrypoints.openai.api_server_langchain \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--model_name THUDM/chatglm3-6b \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--tok_dir ./chatglm3-6b \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--weight_dir ./chatglm3-6b-2npu-dataset \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--temperature 0.8 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--top_p 0.8 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--max_output_len 256 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--port 18000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--device 0 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 忽略部分回显</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---------------------------- Model Info Begin ----------------------------</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model name: THUDM/chatglm3-6b</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">npus: [0, 1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">total slot number: 157053</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">slot number per segment: 256</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">total segment number: 613</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">bytes per slot: 14336</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">temporary cpp dir: /home/superadmin/.cache/stc_llm_dnn/THUDM/chatglm3-6b</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer dir: ./chatglm3-6b</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">weight dir: ./chatglm3-6b-2npu-dataset</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">embedding on host: False</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">output on host: False</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dma preload: True</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">max sequence length: 8192</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compress_factor: 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">quant_type: fp16</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---------------------------- Model Info End ----------------------------</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 忽略部分回显</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">INFO:     Application startup complete.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">INFO:     Uvicorn running on http://0.0.0.0:18000 (Press CTRL+C to quit)</span><br></span></code></pre></div></div>
</li>
<li>
<p>在客户端调用completions或者chat_completions接口发起推理请求。</p>
<ul>
<li>
<p>补全文本示例，向LLM提供起始文本，LLM自动将起始文本补全为一段话、文章等形式。</p>
<ul>
<li>
<p>curl方式：</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 调用completions接口示例</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ curl http://172.16.xxx.xxx:18000/v1/completions \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    -H &quot;Content-Type: application/json&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    -d &#x27;{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;model&quot;: &quot;THUDM/chatglm3-6b&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;prompt&quot;: &quot;中国位于&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;max_tokens&quot;: 1024,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;temperature&quot;: 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> {&quot;model&quot;:&quot;THUDM/chatglm3-6b&quot;,&quot;object&quot;:&quot;text_completion&quot;,&quot;created&quot;:1720773513,&quot;choices&quot;:[{&quot;index&quot;:0,&quot;text&quot;:&quot;亚洲的东部，是一个多民族国家，拥有悠久的历史和灿烂的文化。中国有着丰富的自然资源，包括煤炭、石油、天然气、金属矿产等。同时，中国还拥有众多美丽的风景，如长城、故宫、黄山、张家界等。\n \n中国是一个农业大国，农作物包括粮食、蔬菜、水果、棉花、油料等。中国也是世界上最大的蔬菜生产国之一，蔬菜种植面积和产量都非常高。此外，中国还有丰富的畜牧业资源，包括猪肉、牛肉、羊肉、禽类等。\n\n中国有着众多的人口，人口数量庞大，城市化进程快速。中国是一个多民族国家，拥有56个民族，汉族是最大的民族，占总人口的近90%。除了汉族外，中国还有壮族、回族、藏族、维吾尔族、蒙古族、朝鲜族等55个少数民族。\n\n中国是一个历史悠久的国家，拥有悠久的历史和灿烂的文化。中国有着丰富的自然资源，包括煤炭、石油、天然气、金属矿产等。同时，中国还拥有众多美丽的风景，如长城、故宫、黄山、张家界等。中国有着众多的文化底蕴，包括儒家文化、道家文化、佛教文化等。\n\n中国是一个农业大国，农作物包括粮食、蔬菜、水果、棉花、油料等。中国也是世界上最大的蔬菜生产国之一，蔬菜种植面积和产量都非常高。此外，中国还有丰富的畜牧业资源，包括猪肉、牛肉、羊肉、禽类等。\n\n中国有着众多的人口，人口数量庞大，城市化进程快速。中国是一个多民族国家，拥有56个民族，汉族是最大的民族，占总人口的近90%。除了汉族外，中国还有壮族、回族、藏族、维吾尔族、蒙古族、朝鲜族等55个少数民族。\n\n中国是一个历史悠久的国家，拥有悠久的历史和灿烂的文化。中国有着丰富的自然资源，包括煤炭、石油、天然气、金属矿产等。同时，中国还拥有众多美丽的风景，如长城、故宫、黄山、张家界等。中国有着众多的文化底蕴，包括儒家文化、道家文化、佛教文化等。&quot;,&quot;finish_reason&quot;:&quot;stop&quot;}]}</span><br></span></code></pre></div></div>
</li>
<li>
<p>Python脚本方式：</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 调用completions接口示例</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ pip3 install openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ cat test_chatglm3-6b-completions.py</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from openai import OpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">openai_api_key = &quot;EMPTY&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">openai_api_base = &quot;http://172.16.xxx.xxx:18000/v1&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">client = OpenAI(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    api_key=openai_api_key,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    base_url=openai_api_base,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">completion = client.completions.create(model=&quot;THUDM/chatglm3-6b&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                      prompt=&quot;中国位于&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(&quot;Completion result:&quot;, completion)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ python3 test_chatglm3-6b-completions.py</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Completion result: Completion(id=None, choices=[CompletionChoice(finish_reason=&#x27;stop&#x27;, index=0, logprobs=None, text=&#x27;亚洲的东部，是一个多民族国家，有 56 个民族。中国是一个农业大国，农业劳动力资源丰富，农业 output value 农业增加值 农业劳动生产率 农业资源利用效率高。中国是一个工业大国,工业发展水平较高,拥有许多著名的企业和品牌。中国的经济发展水平较高,人均 GDP 高于世界平均水平。\n 中国是一个多民族国家，拥有 56 个民族。汉族是最大的民族，占总人口的近 90%。&#x27;)], created=1720774449, model=&#x27;THUDM/chatglm3-6b&#x27;, object=&#x27;text_completion&#x27;, system_fingerprint=None, usage=None)</span><br></span></code></pre></div></div>
</li>
</ul>
</li>
<li>
<p>发起聊天示例，向LLM提供系统角色信息以及聊天输入，LLM理解输入并按其系统角色回复用户。</p>
<ul>
<li>
<p>curl方式：</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 调用chat_completions接口示例</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ curl http://172.16.xxx.xxx:18000/v1/chat/completions \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    -H &quot;Content-Type: application/json&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    -d &#x27;{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;model&quot;: &quot;THUDM/chatglm3-6b&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;messages&quot;: [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;你是一个资深体育评论员，可以为用户提供足球世界杯的权威信息，回答尽量精简。&quot;},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你好，谁赢得了2002年足球世界杯的冠军？&quot;}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> {&quot;model&quot;:&quot;THUDM/chatglm3-6b&quot;,&quot;object&quot;:&quot;chat.completion&quot;,&quot;choices&quot;:[{&quot;index&quot;:0,&quot;message&quot;:{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;\n 2002年足球世界杯冠军是巴西。&quot;,&quot;function_call&quot;:null},&quot;finish_reason&quot;:&quot;stop&quot;}],&quot;created&quot;:1720774488}</span><br></span></code></pre></div></div>
</li>
<li>
<p>Python脚本示例：</p>
<div class="language-Bash language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 调用chat_completions接口示例</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ pip3 install openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ cat test_chatglm3-6b-chat-completions.py</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from openai import OpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">openai_api_key = &quot;EMPTY&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">openai_api_base = &quot;http://172.16.xxx.xxx:18000/v1&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">client = OpenAI(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    api_key=openai_api_key,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    base_url=openai_api_base,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chat_response = client.chat.completions.create(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model=&quot;THUDM/chatglm3-6b&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    messages=[</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;你是一个资深体育评论员，可以为用户提供足球世界杯的权威信息，回答尽量精简。&quot;},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你好，谁赢得了2002年足球世界杯的冠军？&quot;},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(&quot;Chat response:&quot;, chat_response)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ python3 test_chatglm3-6b-chat-completions.py</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Chat response: ChatCompletion(id=None, choices=[Choice(finish_reason=&#x27;stop&#x27;, index=0, logprobs=None, message=ChatCompletionMessage(content=&#x27;\n 2002年足球世界杯冠军是巴西。&#x27;, role=&#x27;assistant&#x27;, function_call=None, tool_calls=None))], created=1720774627, model=&#x27;THUDM/chatglm3-6b&#x27;, object=&#x27;chat.completion&#x27;, service_tier=None, system_fingerprint=None, usage=None)</span><br></span></code></pre></div></div>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="completions参数">completions参数<a href="#completions参数" class="hash-link" aria-label="Direct link to completions参数" title="Direct link to completions参数" translate="no">​</a></h3>
<table><thead><tr><th><strong>参数名</strong></th><th><strong>是否必填</strong></th><th><strong>数据类型</strong></th><th><strong>示例</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td>model</td><td>是</td><td>str</td><td>THUDM/chatglm3-6b</td><td>待调用模型的名称，一般为启动推理服务时所运行的模型名称。</td></tr><tr><td>prompt</td><td>是</td><td>str</td><td>中国位于</td><td>描述要求模型完成的任务，例如补全文本、回答问题。</td></tr><tr><td>temperature</td><td>否</td><td>float</td><td>0.8</td><td>超参数之一，控制生成输出的随机性，值越低保证更多的确定性，值越高引入更多的随机性。需要在部署模型时将custom_parameters配置为True才可以修改，数值范围为[0.0, 2.0]。</td></tr><tr><td>top_p</td><td>否</td><td>float</td><td>0.8</td><td>超参数之一，在生成输出抽样时排除累积概率低于该值的token。需要在部署模型时将custom_parameters配置为True才可以修改，数值范围为(0.0, 1.0]。</td></tr><tr><td>top_k</td><td>否</td><td>int</td><td>1</td><td>超参数之一，在生成输出抽样时只在概率top k个token中进行。需要在部署模型时将custom_parameters配置为True才可以修改，数值范围为[1, 词表长度]。</td></tr><tr><td>max_tokens</td><td>否</td><td>int</td><td>256</td><td>最长返回的token数量。数值范围为[1, 模型支持上下文长度]。</td></tr><tr><td>logprobs</td><td>否</td><td>bool</td><td>true</td><td>需要在部署模型时将custom_parameters配置为True才可以修改。<br>true：启用返回生成输出token的对数概率。<br>false：默认值，禁用返回生成输出token的对数概率。</td></tr><tr><td>top_logprobs</td><td>否</td><td>int</td><td>5</td><td>指定在每个生成输出token时一并返回最有可能的token数量，每个token都带有对数概率。需要将logprobs开关设置为true方可生效，数值范围为[0, 5]。</td></tr><tr><td>stream</td><td>否</td><td>bool</td><td>true</td><td>true：启用流式传输，当模型生成一定数量的token后，立即将token传输给客户端，而不是等所有token生成完毕后，从而减少用户的等待时间。<br>false：默认值，禁用流式传输，等所有token生成完毕后，再将所有token传输给客户端。</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="chat_completions参数">chat_completions参数<a href="#chat_completions参数" class="hash-link" aria-label="Direct link to chat_completions参数" title="Direct link to chat_completions参数" translate="no">​</a></h3>
<table><thead><tr><th><strong>参数名</strong></th><th><strong>是否必填</strong></th><th><strong>数据类型</strong></th><th><strong>示例</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td>model</td><td>是</td><td>str</td><td>THUDM/chatglm3-6b</td><td>待调用模型的名称，一般为启动推理服务时所运行的模型名称。</td></tr><tr><td>messages</td><td>是</td><td>dict</td><td>？？？</td><td>传给模型的消息对象，您可以通过字段组合控制模型行为，获得预期的输出。<br>role字段：用于设置角色，例如system（系统角色）、user（用户角色）。<br>content字段：用于描述要求，例如通过system描述助手扮演的系统角色，通过user描述用户要求助手完成创作文章、回答问题等任务。</td></tr><tr><td>temperature</td><td>否</td><td>float</td><td>0.8</td><td>超参数之一，控制生成输出的随机性，值越低保证更多的确定性，值越高引入更多的随机性。需要在部署模型时将custom_parameters配置为True才可以修改，数值范围为[0.0, 2.0]。</td></tr><tr><td>top_p</td><td>否</td><td>float</td><td>0.8</td><td>超参数之一，在生成输出抽样时排除累积概率低于该值的token。需要在部署模型时将custom_parameters配置为True才可以修改，数值范围为(0.0, 1.0]。</td></tr><tr><td>top_k</td><td>否</td><td>int</td><td>1</td><td>超参数之一，在生成输出抽样时只在概率top k个token中进行。需要在部署模型时将custom_parameters配置为True才可以修改，数值范围为[1, 词表长度]。</td></tr><tr><td>max_tokens</td><td>否</td><td>int</td><td>256</td><td>最长返回的token数量。数值范围为[1, 模型支持上下文长度]。</td></tr><tr><td>logprobs</td><td>否</td><td>bool</td><td>true</td><td>需要在部署模型时将custom_parameters配置为True才可以修改。<br>true：启用返回生成输出token的对数概率。<br>false：默认值，禁用返回生成输出token的对数概率。</td></tr><tr><td>top_logprobs</td><td>否</td><td>int</td><td>5</td><td>指定在每个生成输出token时一并返回最有可能的token数量，每个token都带有对数概率。需要将logprobs开关设置为true方可生效，数值范围为[0, 5]。</td></tr><tr><td>stream</td><td>否</td><td>bool</td><td>true</td><td>true：启用流式传输，当模型生成一定数量的token后，立即将token传输给客户端，而不是等所有token生成完毕后，从而减少用户的等待时间。<br>false：默认值，禁用流式传输，等所有token生成完毕后，再将所有token传输给客户端。</td></tr></tbody></table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="监控推理指标">监控推理指标<a href="#监控推理指标" class="hash-link" aria-label="Direct link to 监控推理指标" title="Direct link to 监控推理指标" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="前提条件-1">前提条件<a href="#前提条件-1" class="hash-link" aria-label="Direct link to 前提条件" title="Direct link to 前提条件" translate="no">​</a></h3>
<ul>
<li>已在服务端启动推理服务。</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="指标类型">指标类型<a href="#指标类型" class="hash-link" aria-label="Direct link to 指标类型" title="Direct link to 指标类型" translate="no">​</a></h3>
<p>STC_LLM基于Prometheus、Grafana生态实现了监控功能，遵循Prometheus expression语法添加需要监控的推理指标即可。支持的推理指标包括：</p>
<table><thead><tr><th><strong>推理指标</strong></th><th><strong>推理指标含义</strong></th><th><strong>Prometheus expression示例</strong></th></tr></thead><tbody><tr><td>prompt处理吞吐</td><td>每秒处理输入prompt token的吞吐量</td><td>stc_llm<div></div></td></tr><tr><td>generation处理吞吐</td><td>每秒输出token的吞吐量</td><td>stc_llm<div></div></td></tr><tr><td>推理次数</td><td>启动推理服务后完成推理的次数</td><td>stc_llm<div></div></td></tr><tr><td>首token时延</td><td>输出首字token花费的时间</td><td>stc_llm<div></div></td></tr><tr><td>任务推理总时延</td><td>完成单轮输出花费的时间</td><td>stc_llm<div></div></td></tr><tr><td>任务decoder时延</td><td>从输出首字token开始，到完成单轮输出所花费的时间</td><td>stc_llm<div></div></td></tr><tr><td>avg generation latency</td><td>输出单位token所花费的时间</td><td>stc_llm<div></div></td></tr><tr><td>running tasks count</td><td>进行中的对话任务数量</td><td>stc_llm<div></div></td></tr><tr><td>swapped tasks count</td><td>因故停止的对话任务数量</td><td>stc_llm<div></div></td></tr><tr><td>waiting tasks count</td><td>等待中的对话任务数量</td><td>stc_llm<div></div></td></tr><tr><td>prompt tokens total count</td><td>输入prompt token的总数量</td><td>stc_llm<div></div></td></tr><tr><td>generation tokens total count</td><td>输出token的总数量</td><td>stc_llm<div></div></td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="服务端操作">服务端操作<a href="#服务端操作" class="hash-link" aria-label="Direct link to 服务端操作" title="Direct link to 服务端操作" translate="no">​</a></h3>
<p>您需要在服务端安装Prometheus、Grafana并确保相关服务正常运行。</p>
<ol>
<li>
<p>安装Prometheus。请根据服务器情况选择合适的安装方式，例如APT源、离线安装包等，相关说明可以参见<a href="https://github.com/prometheus/prometheus" target="_blank" rel="noopener noreferrer">Prometheus官方开源项目</a>。</p>
</li>
<li>
<p>修改Prometheus配置，默认配置文件为<code>/etc/prometheus/prometheus.yml</code>。</p>
<ul>
<li>
<p>提供Prometheus服务的地址，默认端口号为9090。</p>
<div class="language-YAML language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">job_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;prometheus&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">static_configs</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">targets</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;localhost:9090&quot;</span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre></div></div>
</li>
<li>
<p>监控推理服务的地址，在对应job（即通过stc_llm.entrypoints.openai.api_server启动的推理服务）的<code>scrape_configs</code>字段下添加IP地址和端口号即可。</p>
<div class="language-YAML language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">job_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;openai_api&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">scrape_interval</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> 5s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">static_configs</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">targets</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;localhost:18000&quot;</span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre></div></div>
</li>
</ul>
</li>
<li>
<p>启动Prometheus服务并确认服务状态。</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ sudo systemctl start prometheus</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ sudo systemctl status prometheus</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">prometheus.service - Prometheus</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     Loaded: loaded (/etc/systemd/system/prometheus.service; enabled; vendor preset: enabled)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     Active: active (running) since Mon 2024-08-19 16:24:11 CST; 1h 6min ago</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Main PID: 3112690 (prometheus)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      Tasks: 53 (limit: 629145)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     Memory: 48.4M</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     CGroup: /system.slice/prometheus.service</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">             └─3112690 /usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yml --storage.tsdb.path /var/lib/prometheus/ --web.console.templates=/etc/prometheus/consoles --web.console.libra&gt;</span><br></span></code></pre></div></div>
</li>
<li>
<p>安装Grafana。请根据服务器情况选择合适的安装方式，例如APT源、离线安装包等，相关说明可以参见<a href="https://github.com/grafana/grafana" target="_blank" rel="noopener noreferrer">Grafana官方开源项目</a>。</p>
</li>
<li>
<p>修改Grafana配置，默认配置文件为<code>/etc/grafana/grafana.ini</code>。</p>
<ul>
<li>
<p>提供Grafana服务的地址，默认端口号为3000。</p>
</li>
<li>
<p>登录Grafana Web端的用户名和密码。</p>
<div class="language-YAML language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">http_port = 3000</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">admin_user = admin</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">admin_password = 123.com</span><br></span></code></pre></div></div>
</li>
</ul>
</li>
<li>
<p>启动Grafana服务并确认服务状态。</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ sudo systemctl start grafana-server</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ sudo systemctl status grafana-server</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">grafana-server.service - Grafana instance</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     Loaded: loaded (/lib/systemd/system/grafana-server.service; disabled; vendor preset: enabled)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     Active: active (running) since Mon 2024-08-19 10:01:25 CST; 7h ago</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       Docs: http://docs.grafana.org</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Main PID: 2970010 (grafana)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      Tasks: 38 (limit: 629145)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     Memory: 53.8M</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     CGroup: /system.slice/grafana-server.service</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">             └─2970010 /usr/share/grafana/bin/grafana server --config=/etc/grafana/grafana.ini --pidfile=/run/grafana/grafana-server.pid --packaging=deb cfg:default.paths.logs=/var/log/grafana cfg:defaul&gt;</span><br></span></code></pre></div></div>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="web端操作prometheus">Web端操作（Prometheus）<a href="#web端操作prometheus" class="hash-link" aria-label="Direct link to Web端操作（Prometheus）" title="Direct link to Web端操作（Prometheus）" translate="no">​</a></h3>
<p>Prometheus提供了指标收集和告警等监控功能，您可以登录Prometheus的Web页面管理需要监控的推理指标。</p>
<ol>
<li>
<p>访问Prometheus Web页面。如果Prometheus服务使用了默认端口，则Web页面地址为<code>http://{server_ip}:9090</code>。</p>
</li>
<li>
<p>单击<strong>Add Panel</strong>添加指标面板。</p>
</li>
<li>
<p>在输入框中填写Prometheus expression，以监控THUDM/chatglm3-6b模型的generation吞吐量为例，填写<code>stc_llm:avg_generation_throughput_toks_per_s{model_name=&quot;THUDM/chatglm3-6b&quot;}</code>。</p>
</li>
<li>
<p>单击<strong>Execute</strong>完成指标添加。</p>
</li>
<li>
<p>单击<strong>Graph</strong>，调整时间范围至执行了推理任务的时间段，即可查看到对应的推理指标。</p>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/stc_llm-03-ce104fb2f80c58f8c194683673cd3f94.png" width="1280" height="598" class="img_ev3q"></p>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="web端操作grafana">Web端操作（Grafana）<a href="#web端操作grafana" class="hash-link" aria-label="Direct link to Web端操作（Grafana）" title="Direct link to Web端操作（Grafana）" translate="no">​</a></h3>
<p>Grafana提供了丰富和美观的可视化功能，使用时将Prometheus添加为数据源并创建Dashboard汇总Panel，即可一站式多维度展示推理指标。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="登录grafana">登录Grafana<a href="#登录grafana" class="hash-link" aria-label="Direct link to 登录Grafana" title="Direct link to 登录Grafana" translate="no">​</a></h4>
<ol>
<li>访问Grafana Web页面。如果Grafana服务使用了默认端口，则Web页面地址为<code>http://{server_ip}:3000</code>。</li>
<li>输入配置的用户名和密码。</li>
</ol>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="添加prometheus数据源">添加Prometheus数据源<a href="#添加prometheus数据源" class="hash-link" aria-label="Direct link to 添加Prometheus数据源" title="Direct link to 添加Prometheus数据源" translate="no">​</a></h4>
<ol>
<li>
<p>在左侧导航栏，单击<strong>Connections</strong> &gt; <strong>Data sources</strong>。</p>
</li>
<li>
<p>单击<strong>Add datasource</strong>。</p>
</li>
<li>
<p>选择<strong>Prometheus</strong>。</p>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/stc_llm-04-2d4b4bd70ac388f727f5c0a4c22617e3.png" width="1280" height="513" class="img_ev3q"></p>
</li>
<li>
<p>在Settings页面，完成Name、Prometheus server URL等配置，然后单击**Save &amp; Test。**提示<code>Successfully queried the Prometheus API.</code>，即代表数据源添加成功。</p>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/stc_llm-05-c4a872030cd9a65231abadb517ce0780.png" width="1280" height="543" class="img_ev3q"></p>
</li>
</ol>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="创建stc_llm-dashboard">创建STC_LLM Dashboard<a href="#创建stc_llm-dashboard" class="hash-link" aria-label="Direct link to 创建STC_LLM Dashboard" title="Direct link to 创建STC_LLM Dashboard" translate="no">​</a></h4>
<ol>
<li>
<p>在左侧导航栏，单击<strong>Dashboards</strong>。</p>
</li>
<li>
<p>单击<strong>New</strong> &gt; <strong>New dashboard</strong>。</p>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/stc_llm-06-c1be2a06c8ec376c0b939c244cc64a8c.png" width="1280" height="280" class="img_ev3q"></p>
</li>
<li>
<p>单击<strong>Add visualization</strong>。</p>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/stc_llm-07-fac2c22d70b1848d8411470776583a5b.png" width="901" height="467" class="img_ev3q"></p>
</li>
<li>
<p>选择已添加的Prometheus数据源。</p>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/stc_llm-08-7590355785434bbe6855bb316566ebde.png" width="1180" height="698" class="img_ev3q"></p>
</li>
<li>
<p>添加Panel。切换到Code模式，在输入框中填写Prometheus expression，以监控THUDM/chatglm3-6b模型的推理次数为例，填写<code>stc_llm:time_to_inference_count{model_name=&quot;THUDM/chatglm3-6b&quot;}</code>，单击<strong>Run queries</strong>查看效果，然后单击<strong>Save</strong>。</p>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/stc_llm-09-83382ebe46319483353cd7b5c40e8bff.png" width="1280" height="598" class="img_ev3q"></p>
</li>
<li>
<p>按提示填入信息，然后单击<strong>Save</strong>。</p>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/stc_llm-10-0cbd9a123bc1b5dd04bb5e69ce54685c.png" width="952" height="402" class="img_ev3q"></p>
</li>
<li>
<p>在Dashboards页面即可看到新添加的STC_LLM Dashboard。</p>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/stc_llm-11-07140134febc592e08077200b8012f86.png" width="1280" height="598" class="img_ev3q"></p>
</li>
<li>
<p>进入STC_LLM Dashboard，即可查看已添加的Panel。</p>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/stc_llm-12-4848b5600a30637554157fce5d3ef79f.png" width="1280" height="598" class="img_ev3q"></p>
</li>
</ol>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="编辑dashboard中的panel">编辑Dashboard中的Panel<a href="#编辑dashboard中的panel" class="hash-link" aria-label="Direct link to 编辑Dashboard中的Panel" title="Direct link to 编辑Dashboard中的Panel" translate="no">​</a></h4>
<ol>
<li>
<p>在左侧导航栏，单击<strong>Dashboards</strong>。</p>
</li>
<li>
<p>单击STC_LLM Dashboard。</p>
</li>
<li>
<p>在待修改Panel右上角，单击Menu图标 &gt; <strong>Edit</strong>。</p>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/stc_llm-13-672e85ba99b25e9ea28091de50babc3f.png" width="802" height="306" class="img_ev3q"></p>
</li>
<li>
<p>按需修改Panel信息，例如将Title修改为推理次数，然后单击<strong>Save</strong>。</p>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/stc_llm-14-190c1ce8e36134a69200454f25960323.png" width="1280" height="598" class="img_ev3q"></p>
</li>
<li>
<p>按需填写信息，然后单击<strong>Save</strong>。</p>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/stc_llm-15-f1c982b23e5eed02ba6b8ae9588e53bb.png" width="952" height="304" class="img_ev3q"></p>
</li>
</ol>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="为dashboard添加新panel">为Dashboard添加新Panel<a href="#为dashboard添加新panel" class="hash-link" aria-label="Direct link to 为Dashboard添加新Panel" title="Direct link to 为Dashboard添加新Panel" translate="no">​</a></h4>
<ol>
<li>
<p>在左侧导航栏，单击<strong>Dashboards</strong>。</p>
</li>
<li>
<p>单击STC_LLM Dashboard。</p>
</li>
<li>
<p>在Dashboard中单击<strong>Add</strong> &gt; <strong>Visualization</strong>。</p>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/stc_llm-16-5b99a4172b514d915afa16adc9499b85.png" width="1280" height="598" class="img_ev3q"></p>
</li>
<li>
<p>添加Panel。切换到Code模式，在输入框中填写Prometheus expression，以监控THUDM/chatglm3-6b模型的prompt处理吞吐和generation处理吞吐为例，分别填写<code>stc_llm:avg_prompt_throughput_toks_per_s{model_name=&quot;THUDM/chatglm3-6b&quot;}</code>和<code>stc_llm:avg_generation_throughput_toks_per_s{model_name=&quot;THUDM/chatglm3-6b&quot;}</code>，单击<strong>Run queries</strong>查看效果，然后单击<strong>Save</strong>。</p>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/stc_llm-17-35b134636361ae4412e135f8b338be26.png" width="1280" height="598" class="img_ev3q"></p>
</li>
<li>
<p>按要求填入信息，然后单击<strong>Save</strong>。</p>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/stc_llm-18-b8653820cadf6056396c2ef702ccbc51.png" width="944" height="314" class="img_ev3q"></p>
</li>
<li>
<p>进入进入STC_LLM Dashboard，即可查看展示效果。</p>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/stc_llm-19-233a6e669b8fe4569825db22e83d4a9c.png" width="1280" height="598" class="img_ev3q"></p>
</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/希姆计算软件产品/STCRP使用指南/STC_LLM使用指南.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/希姆计算软件产品/STCRP使用指南/MLTC使用指南"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">MLTC使用指南</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/希姆计算软件产品/STCRP使用指南/npu-exporter使用说明"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">npu-exporter使用说明</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#stc_llm概述" class="table-of-contents__link toc-highlight">STC_LLM概述</a></li><li><a href="#部署模型" class="table-of-contents__link toc-highlight">部署模型</a><ul><li><a href="#前提条件" class="table-of-contents__link toc-highlight">前提条件</a></li><li><a href="#部署流程" class="table-of-contents__link toc-highlight">部署流程</a></li><li><a href="#模型配置" class="table-of-contents__link toc-highlight">模型配置</a></li><li><a href="#问题排查" class="table-of-contents__link toc-highlight">问题排查</a></li></ul></li><li><a href="#提供推理服务" class="table-of-contents__link toc-highlight">提供推理服务</a><ul><li><a href="#使用流程" class="table-of-contents__link toc-highlight">使用流程</a></li><li><a href="#completions参数" class="table-of-contents__link toc-highlight">completions参数</a></li><li><a href="#chat_completions参数" class="table-of-contents__link toc-highlight">chat_completions参数</a></li></ul></li><li><a href="#监控推理指标" class="table-of-contents__link toc-highlight">监控推理指标</a><ul><li><a href="#前提条件-1" class="table-of-contents__link toc-highlight">前提条件</a></li><li><a href="#指标类型" class="table-of-contents__link toc-highlight">指标类型</a></li><li><a href="#服务端操作" class="table-of-contents__link toc-highlight">服务端操作</a></li><li><a href="#web端操作prometheus" class="table-of-contents__link toc-highlight">Web端操作（Prometheus）</a></li><li><a href="#web端操作grafana" class="table-of-contents__link toc-highlight">Web端操作（Grafana）</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/希姆计算术语表">希姆计算术语</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>